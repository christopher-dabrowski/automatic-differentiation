%% LaTeX template based on the https://mirrors.mit.edu/CTAN/macros/latex/contrib/IEEEtran/bare_conf.tex

\documentclass[conference,a4paper]{IEEEtran}
\input{config}

\begin{document}
\title{State of Automatic Differentiation\\ Literature Review}

\author{
\IEEEauthorblockN{Krzysztof Dąbrowski}
\IEEEauthorblockA{Faculty of Electrical Engineering\\
Warsaw University of Technology\\
Warsaw 00-662, Poland\\
Email: krzysztof.dabrowski7.stud@pw.edu.pl
}}

\maketitle

% Mój dokument ma zająć od połowy do całej strony

\section{Introduction and Research Context}
% omówienie kontekstu badawczego i znaczenia tematu w literaturze

In my research I'll be studding fast implementation of automatic differentiation in The Julia programming language \cite{JuliaLanguage:Homepage}.
The topic of automatic differentiation is very important in the fields of machine learning and optimization.

The differentiation operations are used in almost all fields of science and engineering.
The differentiation allows to calculate how the function changes based on the input change.
This information is very useful in most optimization problems.

Automatic differentiation is a one of the techniques used to calculate the derivative of a function in a algorithmic way.
In a fields when the exact function is known, but the entire function is complicated, the automatic differentiation technique is usually chosen \cite{baydin2018automatic}.


\section{Current Research}
% podsumowanie najważniejszych badań (+ ew. wskazanie braków, rozbieżności)
% Przejście w tył
The are three main methods used to calculate the derivative of a function automatically:
\begin{itemize}
    \item \textbf{Symbolic differentiation} - symbolic representation of the function is transformed to the derivative form similar to the manual differentiation. This method is very accurate, but it tends to be slow or impractical for complex functions \cite{durrbaum2002comparison},
    \item \textbf{Numerical differentiation} - this method uses numerical approximation to calculate the derivative. It is commonly used when the exact function is not known. The numerical differentiation is usually fast, but the results can be inaccurate \cite{cullum1971numerical},
    \item \textbf{Automatic differentiation} - based on the chain rule. It allows for calculating the derivative of a complex functions while having the machine precision of the calculations \cite{baydin2018automatic}.
\end{itemize}

In my research \textbf{I'll be focusing on the automatic differentiation} as it is both versatile and accurate.
The automatic differentiation is usually implemented in one two gradient accumulation modes.
\paragraph{Forward mode} - the derivative is calculated in the forward direction, starting from the input variables and moving towards the output. The result of the functions is calculated at the same time as the gradient. It is efficient when differentiating functions with few input parameters \cite{revels2016forward}.
\paragraph{Reverse mode} - a two step process is used to calculate the derivative. First the original function value is calculated and each operation dependencies are memorized. After that the derivative is calculated \cite{baydin2018automatic}.

Some researchers are proposing that the symbolic differentiation can also be used even in complex functions \cite{laue2019equivalence}.

\section{Research Justification}
% uzasadnienie potrzeby przeprowadzenia własnego badania, wskazanie, w jaki sposób wpisuje się ono w istniejącą literaturę
The main algorithms used for automatic differentiation are well research in the popular prograding language like C, but there are not as well studied in Julia.
As Julia is focused on high performance and ease of use, especially in academic fields, I see a lof of value in expiring how the automatic differentiation can be implemented in Julia in a performance oriented way.
As the automatic differentiation is a building bloc of many algorithmic exploration if its effient implementation in academic focused programming language can be a stepping stone for future researchers.

\section{Literature Impact}
% wnioski wynikające z analizy literaturowej i ich implikacje dla prowadzonych badań
% Skupienie na przejściu w tył: graf obliczeniowy lub metaprogramowanie
Based on my review of the literature, I have decided to focus my research on the automatic differentiation done in the reverse mode.
This metod will allow me to research the usage of the automatic differentiation in the Julia in applications where the function has multiple input parameters, such as in the artificial neural networks \cite{wang2003artificial}.

\bibliographystyle{IEEEtran}
\bibliography{Bibliography}

\end{document}

